{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CS522 - Final Project\n",
    "The objective of the final project is to integrate various machine learning techniques to achieve the best performance. Final project is a group effort. Each group can have 4-5 members. You are required to apply ALL techniques learned in this semester.\n",
    "\n",
    "## Schedule\n",
    "- (5) Milestone 1 (Due 11/4): Group Formation and Topic selection. Submit through Canvas. Approval and comments will be returned in one day. The same topic cannot be chosen by more than 1 group. The topic follows the first-come first-served rule. So pick a topic as soon as possible.\n",
    "- (5) Milestone 2 - Literature Survey (Due 11/11): Background study including references and state-of-the-art performance on the dataset (2-page report need to be submitted).\n",
    "- (5) Milestone 3 - Prototype 1 (Due 11/18): Prototype, preliminary results and task allocation among group members. Apply at least one learned technique successfully for each component in the pipeline on the chosen dataset and submit a 1-page report.\n",
    "- (5) Milestone 4 - Prototype 2 (Due 12/02): Implement at least two solutions to each component of the pipeline. Determine what metrics to use. Provide performance evaluation results.\n",
    "- (100) Final presentation (Due 12/08)(Presentation slides due the midnight before the presentation on 12/9. Submit through Canvas)\n",
    "- (80) Final report (Due 12/10). Submit through Canvas.\n",
    "\n",
    "## Potential Topics\n",
    "Each group can choose one topic from the following sources. All selection needs to be approved by instructor.\n",
    "- KDD-Cup 1997-2009\n",
    "- Kaggle Competitions\n",
    "- Other topics: You can select a topic yourself from other resources.\n",
    "\n",
    "## Requirement\n",
    "General steps involved in a machine learning problem include\n",
    "- Data collection (raw data)\n",
    "- Feature extraction (how to extract features from the raw data)\n",
    "- Feature selection (dimensionality reduction - Fisher's linear discriminant or PCA)\n",
    "- Classification/Regression methods need to be included\n",
    "    - Supervised learning and Unsupervised learning\n",
    "    - Baysian approaches and non-Baysian approaches\n",
    "    - Parametric and Non-parametric density estimation in supervised learning\n",
    "    - Fusion\n",
    "- Performance evaluation\n",
    "- Feedback system\n",
    "\n",
    "You are required to evaluate the effect of various aspects of the classification/regression process, including but not limited to\n",
    "- the effect of assuming the data is Gaussian-distributed\n",
    "- the effect of assuming parametric pdf vs. non-parametric pdf\n",
    "- the effect of using different prior probability ratio\n",
    "- the effect of using different distance\n",
    "- the effect of knowing the class label\n",
    "- the effect of dimension of the feature space (e.g., changed through dimensionality reduction)\n",
    "- the effect of fusion\n",
    "\n",
    "To be more specific, you need to at least go through the following steps:\n",
    "- Data normalization\n",
    "- Dimensionality reduction\n",
    "    - Classification/Regression with the following\n",
    "    - MPP (case 1, 2, and 3)\n",
    "    - kNN with different k's\n",
    "    - BPNN\n",
    "    - Decision tree\n",
    "    - SVM\n",
    "    - Clustering (kmeans, wta)\n",
    "- Classifier fusion\n",
    "- Evaluation (use n-fold cross validation to generate confusion matrix and ROC curve if applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Data collection (raw data) - Face Mask 12k Images Dataset\n",
    "- URL: [https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset](https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset)\n",
    "\n",
    "This dataset is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.\n",
    "\n",
    "\"All the images with the face mask (~6K) are scrapped from google search and all the images without the face mask are preprocessed from the CelebFace dataset created by Jessica Li (https://www.kaggle.com/jessicali9530). Thank you so much Jessica for providing a wonderful dataset to the community.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# IMPORT OUR OWN FILES\n",
    "\n",
    "from Dataset import *\n",
    "from PreProcessing import *\n",
    "from convolution import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# MISCELLANEOUS ROUTINES\n",
    "\n",
    "# make directory to save generated images to\n",
    "os.makedirs('img', exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1. Read In Data\n",
    "Throughout this project:\n",
    "- 0 corresponds to not wearing a mask\n",
    "- 1 corresponds to wearing a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dataset Init: datasets/face_mask\n",
      "\t- Loading Datasets...\n",
      "\t=> TRAIN\n",
      "\t\t- With Mask: 5000 (50.0%)\n",
      "\t\t- No Mask: 5000 (50.0%)\n",
      "\t\t- Total: 10000\n",
      "\t=> VALIDATION\n",
      "\t\t- With Mask: 400 (50.0%)\n",
      "\t\t- No Mask: 400 (50.0%)\n",
      "\t\t- Total: 800\n",
      "\t=> TEST\n",
      "\t\t- With Mask: 483 (48.69%)\n",
      "\t\t- No Mask: 509 (51.31%)\n",
      "\t\t- Total: 992\n",
      "# Loading Train Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1351.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1409.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:00<00:00, 1421.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Datasets Loaded!\n",
      "# Dataset Info: datasets/face_mask\n",
      "\t- Train: 10000 (84.8%)\n",
      "\t- Validation: 800 (6.78%)\n",
      "\t- Test: 992 (8.41%)\n",
      "\t- Total: 11792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(dataset_dir=os.path.join(\"datasets\", \"face_mask\"))\n",
    "dataset.load_all()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2. Normalizing dataset\n",
    "Need to standardize the size of the images.\n",
    "It is conventional to resize all of the images to the smallest image in the dataset.\n",
    "https://datascience.stackexchange.com/questions/40462/how-to-prepare-the-varied-size-input-in-cnn-prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Performing Feature Set Transformation: t_resize\n",
      "\t- 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'cupy._core.core.ndarray' object has no attribute '__array_interface__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_507342/2435538382.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_resize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/Dataset.py\u001B[0m in \u001B[0;36mtransform\u001B[0;34m(self, x_routine, overwrite)\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\\t- {i + 1}/{len(sets)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx_routine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_routine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_507342/2435538382.py\u001B[0m in \u001B[0;36mt_resize\u001B[0;34m(X)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mt_resize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;31m# resize training data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mPreProcessing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/PreProcessing.py\u001B[0m in \u001B[0;36mresize_images\u001B[0;34m(X, size)\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0msize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m3\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m             \u001B[0mX_new\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPreProcessing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mX_new\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/PreProcessing.py\u001B[0m in \u001B[0;36mresize_image\u001B[0;34m(x, size)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mresize_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresample\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mPIL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLANCZOS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mfromarray\u001B[0;34m(obj, mode)\u001B[0m\n\u001B[1;32m   2760\u001B[0m     \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mversionadded\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1.1\u001B[0m\u001B[0;36m.6\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2761\u001B[0m     \"\"\"\n\u001B[0;32m-> 2762\u001B[0;31m     \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__array_interface__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2763\u001B[0m     \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"shape\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2764\u001B[0m     \u001B[0mndim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'cupy._core.core.ndarray' object has no attribute '__array_interface__'"
     ]
    }
   ],
   "source": [
    "def t_resize(X):\n",
    "    # resize training data\n",
    "    return PreProcessing.resize_images(X, size=(128, 128, 3))\n",
    "\n",
    "\n",
    "dataset.transform(t_resize)\n",
    "\n",
    "\n",
    "def t_grayscale(X):\n",
    "    return PreProcessing.dataset2grayscale(X)\n",
    "\n",
    "\n",
    "dataset_gray = dataset.copy_transform(t_grayscale)\n",
    "\n",
    "\n",
    "def t_scale(X):\n",
    "    return PreProcessing.min_max_scale_dataset(X)\n",
    "\n",
    "\n",
    "dataset.transform(t_scale)\n",
    "dataset_gray.transform(t_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3. Peek at Dataset\n",
    "In order to get a feel for the data, lets look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_img_grid(img, label, size, pos):\n",
    "    \"\"\"\n",
    "    given the image, its label, the size of the grid, and its position on the grid,\n",
    "    create a grid of images displaying images in the dataset\n",
    "    \"\"\"\n",
    "    ax = plt.subplot2grid(size, pos)\n",
    "    ax.tick_params(left=False, right=False, labelleft=False,\n",
    "                   labelbottom=False, bottom=False)\n",
    "    ax.title.set_text(label)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "fig.suptitle('Quick peek at the data')\n",
    "plot_img_grid(dataset_gray.train.X[0], 'No Mask', (2, 3), (0, 0))\n",
    "plot_img_grid(dataset_gray.train.X[1000], 'No Mask', (2, 3), (0, 1))\n",
    "plot_img_grid(dataset_gray.train.X[2000], 'No Mask', (2, 3), (0, 2))\n",
    "plot_img_grid(dataset_gray.train.X[7000], 'Mask', (2, 3), (1, 0))\n",
    "plot_img_grid(dataset_gray.train.X[8001], 'Mask', (2, 3), (1, 1))\n",
    "plot_img_grid(dataset_gray.train.X[9004], 'Mask', (2, 3), (1, 2))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./img/faces.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Feature extraction\n",
    "Objective: how to extract features from the raw data\n",
    "\n",
    "# 2.1. Convolutional Neural Network (CNN)\n",
    "\n",
    "![CNN Hierarchy](img/cnn_hierarchy.png)\n",
    "\n",
    "Build Layers and Sequential Model for the convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_cnn_rgb(flatten: bool):\n",
    "    kernel = np.array([[[1, -1, 1], [-1, 8, -1], [1, -1, 1]], [[1, -1, 1], [-1, 8, -1], [1, -1, 1]],\n",
    "                       [[1, -1, 1], [-1, 8, -1], [1, -1, 1]]])  # 3d kernel needed for 3d image\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv(kernel=kernel, name=\"input_layer\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Pooling2D(pool_size=2, stride=2, padding=0, mode='avg', name=\"pooling1\"))\n",
    "    model.add(Conv(kernel=kernel, name=\"layer1\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Pooling2D(pool_size=2, stride=2, padding=0, mode='avg', name=\"pooling1\"))\n",
    "    if flatten:\n",
    "        model.add(Flatten())\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "test_image = dataset.train.X[0]\n",
    "x = get_cnn_rgb(flatten=False).feedforward(test_image)\n",
    "\n",
    "# display original image\n",
    "plt.imshow(test_image)\n",
    "plt.show()\n",
    "\n",
    "# display convolved image\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_cnn_gray(flatten: bool):\n",
    "    # convolution kernel\n",
    "    # kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) # sharper images\n",
    "    kernel = np.array([[0, -1, 0], [-1, 6, -1], [0, -1, 0]])  # sharper images\n",
    "    # kernel = np.array([[-1, -1, -1], [-1, 0, -1], [-1, -1, -1]])\n",
    "    # kernel = np.array([[[-1, 0, -1], [-1, 0, -1], [-1, 0, -1]],\n",
    "    #                    [[-1, 0, -1], [-1, 0, -1], [-1, 0, -1]],\n",
    "    #                    [[-1, 0, -1], [-1, 0, -1], [-1, 0, -1]]])\n",
    "    # kernel = np.array([[0,1,2,1,0], [1,4,8,4,1], [2,8,16,8,2], [1,4,8,4,1],[0,1,2,1,0]]) # smoothing\n",
    "    # kernel = np.array([[0, 1, 0], [1, 4, 1], [0, 1, 0]])  # gaussian blur\n",
    "\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(Conv(kernel=kernel, name=\"input_layer\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Pooling2D(mode='avg'))\n",
    "    model.add(Conv(kernel=kernel, name=\"input_layer\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv(kernel=kernel, name=\"input_layer\"))\n",
    "    if (flatten):\n",
    "        model.add(Flatten())\n",
    "    # model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "test_image_gray = dataset_gray.train.X[7345]\n",
    "# feed image through model\n",
    "x = get_cnn_gray(flatten=False).feedforward(test_image_gray)\n",
    "\n",
    "# display original image\n",
    "plt.imshow(test_image_gray, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# display convoluted image\n",
    "plt.imshow(x, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model_cnn_rgb = get_cnn_rgb(flatten=True)\n",
    "model_cnn_gray = get_cnn_gray(flatten=True)\n",
    "\n",
    "def t_conv_rgb(X):\n",
    "    conv = np.array([model_cnn_rgb.feedforward(x) for x in tqdm(X)])\n",
    "    return conv\n",
    "\n",
    "def t_conv_gray(X):\n",
    "    conv = np.array([model_cnn_gray.feedforward(x) for x in tqdm(X)])\n",
    "    return conv\n",
    "\n",
    "dataset.transform(t_conv_rgb)\n",
    "dataset_gray.transform(t_conv_gray)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save transformed dataset objects to file\n",
    "dirpath = os.path.join('datasets', 'face_mask_pickled')\n",
    "\n",
    "dataset.save_gzip(dir_path=dirpath, file_name=\"dataset_conv.pkl.gzip\", overwrite=True)\n",
    "dataset_gray.save_gzip(dir_path=dirpath, file_name=\"dataset_gray_conv.pkl.gzip\", overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. Feature Selection\n",
    "Dimensionality Reduction - Fisher's linear discriminant or PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"# Train\")\n",
    "X_train_norm = np.array(dataset.train.X)\n",
    "X_train_gray_norm = np.array(dataset_gray.train.X)\n",
    "print(f\"* X_train_norm shape {X_train_norm.shape}\")\n",
    "print(f\"* X_train_gray_norm shape {X_train_gray_norm.shape}\")\n",
    "print(f\"* y_train shape {dataset.train.y.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"# Validation\")\n",
    "X_validation_norm = np.array(dataset.validation.X)\n",
    "X_validation_gray_norm = np.array(dataset_gray.validation.X)\n",
    "print(f\"* X_validation_norm shape {X_validation_norm.shape}\")\n",
    "print(f\"* X_validation_gray_norm shape {X_validation_gray_norm.shape}\")\n",
    "print(f\"* y_validation shape {dataset.validation.y.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"# Test\")\n",
    "X_test_norm = np.array(dataset.test.X)\n",
    "X_test_gray_norm = np.array(dataset_gray.test.X)\n",
    "print(f\"* X_test_norm shape {X_test_norm.shape}\")\n",
    "print(f\"* X_test_gray_norm shape {X_test_gray_norm.shape}\")\n",
    "print(f\"* y_test shape {dataset.test.y.shape}\")\n",
    "print()\n",
    "\n",
    "# Flatten array (without CNN for now until we run and save all images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this might take a while\n",
    "# save the output of the convoluted training examples in case we want to use them later\n",
    "\"\"\"\n",
    "dir_path = os.path.join('datasets', 'face_mask_pickled')\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_conv_dataset(dataset, fn):\n",
    "    if os.path.exists(fn):\n",
    "        with gzip.open(fn, 'rb') as f:\n",
    "            conv = pickle.load(f)\n",
    "    else:\n",
    "        conv = np.array([model.feedforward(x) for x in dataset])\n",
    "        with gzip.open(fn, 'wb') as f:\n",
    "            pickle.dump(conv, f)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "X_train_gray_conv = get_conv_dataset(X_train_gray_norm, os.path.join(dir_path, 'X_train_gray_conv.pkl.gzip'))\n",
    "X_validation_gray_conv = get_conv_dataset(X_validation_gray_norm,\n",
    "                                          os.path.join(dir_path, 'X_validation_gray_conv.pkl.gzip'))\n",
    "X_test_gray_conv = get_conv_dataset(X_test_gray_norm, os.path.join(dir_path, 'X_test_gray_conv.pkl.gzip'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. Classification/Regression methods need to be included\n",
    "- Supervised learning and Unsupervised learning\n",
    "- Baysian approaches and non-Baysian approaches\n",
    "- Parametric and Non-parametric density estimation in supervised learning\n",
    "- Fusion\n",
    "\n",
    "Classification performed with:\n",
    "1. MPP (case 1, 2, and 3)\n",
    "2. kNN with different k's\n",
    "3. BPNN\n",
    "4. Decision tree\n",
    "5. SVM\n",
    "6. Clustering (kmeans, wta)\n",
    "\n",
    "You are required to evaluate the effect of various aspects of the classification/regression process, including but not limited to:\n",
    "- the effect of assuming the data is Gaussian-distributed\n",
    "- the effect of assuming parametric pdf vs. non-parametric pdf\n",
    "- the effect of using different prior probability ratio\n",
    "- the effect of using different distance\n",
    "- the effect of knowing the class label\n",
    "- the effect of dimension of the feature space (e.g., changed through dimensionality reduction)\n",
    "- the effect of fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.1. MPP (case 1, 2, and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mpp import MPPCase1\n",
    "from evaluation import *\n",
    "\n",
    "case_1 = MPPCase1([0.5, 0.5])\n",
    "case_1.fit(X_train_gray_conv, y_train)\n",
    "y_pred = case_1.predict(X_test_gray_conv)\n",
    "\n",
    "cm = get_confusion_matrix(y_test, y_pred, np.unique(y_test))\n",
    "plot_confusion_matrix(cm, np.unique(y_test), 'Case 1 Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.2. kNN with different k's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.3. BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.6. Clustering (KMeans and WTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from data_functions import get_dataset_fn, load_dataset, resize_dataset\n",
    "\n",
    "# plt.imshow(X_train[0])\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(kmeans_image_compress(X_train[0], 3))\n",
    "# plt.show()\n",
    "dataset_dir = os.path.join(\"datasets\", \"face_mask\")\n",
    "size = (128, 128, 3)\n",
    "X_train_resized = resize_dataset(load_dataset(get_dataset_fn(dataset_dir, \"train\")[0][:10]), size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5. Performance evaluation\n",
    "Note: Use n-fold cross validation to generate confusion matrix and ROC curve if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6. Feedback system\n",
    "Maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}