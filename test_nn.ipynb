{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading from Gzip Pickle File: datasets/face_mask_pickled/dataset_gray_conv.pkl.gzip\n",
      "Input Dimension: 3481\n",
      "# Training MLP Network: Sizes=[3481, 1200, 600, 300, 2]\tEpochs=30\tBatch-Size=50\tLearning-Rate=1\n",
      " - Training Data Len: 10000\n",
      " - Validation Data Len: 800\n",
      "# Epochs:\n",
      "\t1. Correct 486/800\t(score: 0.6075\tdelta: 0.6075\tdelta_avg: 0.6075)\n",
      "\t2. Correct 538/800\t(score: 0.6725\tdelta: 0.06499999999999995\tdelta_avg: 0.33625)\n",
      "\t3. Correct 551/800\t(score: 0.68875\tdelta: 0.016249999999999987\tdelta_avg: 0.22958333333333333)\n",
      "\t4. Correct 482/800\t(score: 0.6025\tdelta: -0.08624999999999994\tdelta_avg: 0.150625)\n",
      "\t5. Correct 545/800\t(score: 0.68125\tdelta: 0.07874999999999999\tdelta_avg: 0.13625)\n",
      "\t6. Correct 524/800\t(score: 0.655\tdelta: -0.026249999999999996\tdelta_avg: 0.10916666666666668)\n",
      "\t7. Correct 503/800\t(score: 0.62875\tdelta: -0.026249999999999996\tdelta_avg: 0.08982142857142858)\n",
      "\t8. Correct 577/800\t(score: 0.72125\tdelta: 0.09249999999999992\tdelta_avg: 0.09015625)\n",
      "\t9. Correct 609/800\t(score: 0.76125\tdelta: 0.040000000000000036\tdelta_avg: 0.08458333333333333)\n",
      "\t10. Correct 520/800\t(score: 0.65\tdelta: -0.11124999999999996\tdelta_avg: 0.065)\n",
      "\t11. Correct 563/800\t(score: 0.70375\tdelta: 0.053749999999999964\tdelta_avg: 0.06397727272727273)\n",
      "\t12. Correct 584/800\t(score: 0.73\tdelta: 0.026249999999999996\tdelta_avg: 0.06083333333333333)\n",
      "\t13. Correct 605/800\t(score: 0.75625\tdelta: 0.026249999999999996\tdelta_avg: 0.058173076923076925)\n",
      "\t14. Correct 535/800\t(score: 0.66875\tdelta: -0.08750000000000002\tdelta_avg: 0.04776785714285714)\n",
      "\t15. Correct 498/800\t(score: 0.6225\tdelta: -0.0462499999999999\tdelta_avg: 0.0415)\n",
      "\t16. Correct 609/800\t(score: 0.76125\tdelta: 0.13874999999999993\tdelta_avg: 0.047578125)\n",
      "\t17. Correct 622/800\t(score: 0.7775\tdelta: 0.016249999999999987\tdelta_avg: 0.045735294117647055)\n",
      "\t18. Correct 580/800\t(score: 0.725\tdelta: -0.05249999999999999\tdelta_avg: 0.04027777777777777)\n",
      "\t19. Correct 556/800\t(score: 0.695\tdelta: -0.030000000000000027\tdelta_avg: 0.03657894736842105)\n",
      "\t20. Correct 530/800\t(score: 0.6625\tdelta: -0.03249999999999997\tdelta_avg: 0.033125)\n",
      "\t21. Correct 632/800\t(score: 0.79\tdelta: 0.12750000000000006\tdelta_avg: 0.03761904761904762)\n",
      "\t22. Correct 599/800\t(score: 0.74875\tdelta: -0.04125000000000001\tdelta_avg: 0.03403409090909091)\n",
      "\t23. Correct 615/800\t(score: 0.76875\tdelta: 0.020000000000000018\tdelta_avg: 0.03342391304347826)\n",
      "\t24. Correct 621/800\t(score: 0.77625\tdelta: 0.007499999999999951\tdelta_avg: 0.03234375)\n",
      "\t25. Correct 628/800\t(score: 0.785\tdelta: 0.008750000000000036\tdelta_avg: 0.031400000000000004)\n",
      "\t26. Correct 633/800\t(score: 0.79125\tdelta: 0.006249999999999978\tdelta_avg: 0.030432692307692306)\n",
      "\t27. Correct 603/800\t(score: 0.75375\tdelta: -0.03749999999999998\tdelta_avg: 0.02791666666666667)\n",
      "\t28. Correct 472/800\t(score: 0.59\tdelta: -0.16375000000000006\tdelta_avg: 0.02107142857142857)\n",
      "\t29. Correct 628/800\t(score: 0.785\tdelta: 0.19500000000000006\tdelta_avg: 0.027068965517241382)\n",
      "\t30. Correct 560/800\t(score: 0.7\tdelta: -0.08500000000000008\tdelta_avg: 0.02333333333333333)\n",
      "Converged in 30 epochs with accuracy 0.7 took 310.59 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7,\n [0.6075,\n  0.6725,\n  0.68875,\n  0.6025,\n  0.68125,\n  0.655,\n  0.62875,\n  0.72125,\n  0.76125,\n  0.65,\n  0.70375,\n  0.73,\n  0.75625,\n  0.66875,\n  0.6225,\n  0.76125,\n  0.7775,\n  0.725,\n  0.695,\n  0.6625,\n  0.79,\n  0.74875,\n  0.76875,\n  0.77625,\n  0.785,\n  0.79125,\n  0.75375,\n  0.59,\n  0.785,\n  0.7],\n None,\n 310.5903625488281)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Dataset import *\n",
    "import cupy as cp\n",
    "from bpnn_cuda import BPNN\n",
    "\n",
    "def convert_categories(y_cat):\n",
    "    desired = cp.array([0 if y[0] == 1 else 1 for y in y_cat])\n",
    "    return desired\n",
    "\n",
    "def get_data():\n",
    "    d = Dataset.load_gzip(os.path.join(\"datasets\", \"face_mask_pickled\"), \"dataset_gray_conv.pkl.gzip\")\n",
    "\n",
    "    ndimen = d.train.X.shape[1]\n",
    "\n",
    "    # Structure Training Data for BPNN\n",
    "    training_inputs = [cp.reshape(cp.asarray(x), (ndimen, 1)) for x in d.train.X]\n",
    "    training_results = [cp.asarray(y.reshape(-1, 1)) for y in d.train.y]\n",
    "\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    # Structure Validation Data for BPNN\n",
    "    validation_inputs = [cp.reshape(cp.asarray(x), (ndimen, 1)) for x in d.validation.X]\n",
    "    validation_data = zip(validation_inputs, convert_categories(d.validation.y))\n",
    "    # Structure Testing Data for BPNN\n",
    "    testing_inputs = [cp.reshape(cp.asarray(x), (ndimen, 1)) for x in d.test.X]\n",
    "    testing_data = zip(testing_inputs, convert_categories(d.test.y))\n",
    "\n",
    "    return training_data, validation_data, testing_data, ndimen\n",
    "\n",
    "\n",
    "training_data, validation_data, testing_data, ndimen = get_data()\n",
    "print(f\"Input Dimension: {ndimen}\")\n",
    "\n",
    "ntrials = 1\n",
    "max_epochs = 30\n",
    "init_nc = [ndimen, 1200, 600, 300, 2]\n",
    "init_b = 50\n",
    "init_lr = 1\n",
    "\n",
    "\n",
    "model_BPNN = BPNN(init_nc, verbose=True)\n",
    "final_score, eval_scores, eval_scores_deltas, conv_time = model_BPNN.train(training_data,\n",
    "                                                                           max_epochs=max_epochs,\n",
    "                                                                           batch_size=init_b,\n",
    "                                                                           learning_rate=init_lr,\n",
    "                                                                           evaluation_data=validation_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch vs. Accuracy (Effect of Network Configuration)\n",
      "# Loading from Gzip Pickle File: datasets/face_mask_pickled/dataset_gray_conv.pkl.gzip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_538226/504750624.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     56\u001B[0m               [ndimen, 3000, 2]]\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m \u001B[0mbest_nc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplot_accuracies_hidden_layers_and_nodes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"img\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayers_arr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_538226/504750624.py\u001B[0m in \u001B[0;36mplot_accuracies_hidden_layers_and_nodes\u001B[0;34m(save_dir, layers_arr)\u001B[0m\n\u001B[1;32m     20\u001B[0m             \u001B[0mtraining_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtesting_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mndimen\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m             \u001B[0mnn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBPNN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m             final_score, eval_scores, eval_scores_deltas, conv_time = nn.train(training_data,\n\u001B[0m\u001B[1;32m     23\u001B[0m                                                                                \u001B[0mmax_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m                                                                                \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minit_b\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/bpnn_cuda.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, training_data, max_epochs, batch_size, learning_rate, evaluation_data, evaluation_treshold)\u001B[0m\n\u001B[1;32m     86\u001B[0m                 for k in range(0, n, batch_size)]\n\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m             \u001B[0;31m# For each mini batch run the update function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbatches\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/bpnn_cuda.py\u001B[0m in \u001B[0;36mupdate_batch\u001B[0;34m(self, batch, learning_rate)\u001B[0m\n\u001B[1;32m    135\u001B[0m         \u001B[0mn_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 137\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    138\u001B[0m             \u001B[0;31m# Use back propagation to get the change in weights and biases\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0mdelta_nabla_b\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelta_nabla_w\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackprop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/D/GitHub/classes/CS522/CS522-TeamProject/bpnn_cuda.py\u001B[0m in \u001B[0;36mbackprop\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0mactivation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[0mactivations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# list to store all the activations, layer by layer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0mzs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# list to store all the z vectors, layer by layer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbiases\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m             \u001B[0mz\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/cupy/linalg/_product.py\u001B[0m in \u001B[0;36mdot\u001B[0;34m(a, b, out)\u001B[0m\n\u001B[1;32m     63\u001B[0m     \"\"\"\n\u001B[1;32m     64\u001B[0m     \u001B[0;31m# TODO(okuta): check type\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1008x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracies_hidden_layers_and_nodes(save_dir, layers_arr):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Training Epoch vs. Accuracy (Effect of Network Configuration)\")\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    plt.title(\n",
    "        f\"Training Epoch vs. Accuracy (Effect of Network Configuration)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    best_score = 0\n",
    "    best_config = None\n",
    "\n",
    "    for layers in layers_arr:\n",
    "        final_scores = []\n",
    "        epoch_scores = []\n",
    "        # Run an average over multiple trials\n",
    "        for i in range(ntrials):\n",
    "            # Get data and train the network\n",
    "            training_data, validation_data, testing_data, ndimen = get_data()\n",
    "            nn = BPNN(layers, verbose=False)\n",
    "            final_score, eval_scores, eval_scores_deltas, conv_time = nn.train(training_data,\n",
    "                                                                               max_epochs=max_epochs,\n",
    "                                                                               batch_size=init_b,\n",
    "                                                                               learning_rate=init_lr,\n",
    "                                                                               evaluation_data=validation_data,\n",
    "                                                                               evaluation_treshold=None)\n",
    "            final_scores.append(final_score)\n",
    "            epoch_scores.append(eval_scores)\n",
    "\n",
    "        # Compute the averages over the specified number of trials\n",
    "        final_score_avg = np.average(final_scores)\n",
    "        epoch_scores = np.mean(epoch_scores, axis=0)\n",
    "\n",
    "        print(f'{layers} => {final_score_avg}')\n",
    "        if final_score_avg > best_score:\n",
    "            best_score = final_score_avg\n",
    "            best_config = layers\n",
    "        plt.plot(epoch_scores, label=f'{layers} - {final_score_avg}')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(f'{save_dir}/bpnn_layers_vs_acc', dpi=100)\n",
    "\n",
    "    return best_config\n",
    "\n",
    "\n",
    "layers_arr = [[ndimen, 50, 2],\n",
    "              [ndimen, 100, 2],\n",
    "              [ndimen, 250, 2],\n",
    "              [ndimen, 500, 2],\n",
    "              [ndimen, 1000, 2],\n",
    "              [ndimen, 1500, 2],\n",
    "              [ndimen, 2500, 2],\n",
    "              [ndimen, 3000, 2]]\n",
    "\n",
    "best_nc = plot_accuracies_hidden_layers_and_nodes(\"img\", layers_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_accuracies_mini_batch_size(save_dir, batch_size_arr):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Training Epoch vs. Accuracy (Effect of Batch Size)\")\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    plt.title(f\"Training Epoch vs. Accuracy (Effect of Batch Size)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    best_score = 0\n",
    "    best_config = None\n",
    "\n",
    "    for batch_size in batch_size_arr:\n",
    "        final_scores = []\n",
    "        epoch_scores = []\n",
    "        # Run an average over multiple trials\n",
    "        for i in range(ntrials):\n",
    "            # Get data and train the network\n",
    "            training_data, validation_data, testing_data, ndimen = get_data()\n",
    "            nn = BPNN(best_nc, verbose=False)\n",
    "            final_score, eval_scores, eval_scores_deltas, conv_time = nn.train(training_data,\n",
    "                                                                               max_epochs=max_epochs,\n",
    "                                                                               batch_size=batch_size,\n",
    "                                                                               learning_rate=init_lr,\n",
    "                                                                               evaluation_data=validation_data,\n",
    "                                                                               evaluation_treshold=None)\n",
    "            final_scores.append(final_score)\n",
    "            epoch_scores.append(eval_scores)\n",
    "\n",
    "        # Compute the averages over the specified number of trials\n",
    "        final_score_avg = np.average(final_scores)\n",
    "        epoch_scores = np.mean(epoch_scores, axis=0)\n",
    "\n",
    "        print(f'{batch_size} => {final_score_avg}')\n",
    "        if final_score_avg > best_score:\n",
    "            best_score = final_score_avg\n",
    "            best_config = batch_size\n",
    "        plt.plot(epoch_scores, label=f'{batch_size} - {final_score_avg}')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(f'{save_dir}/bpnn_batch_vs_acc', dpi=100)\n",
    "\n",
    "    return best_config\n",
    "\n",
    "\n",
    "batch_size_arr = [5, 10, 15, 20, 40, 80, 100, 125, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "best_b = plot_accuracies_mini_batch_size(\"img\", batch_size_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_accuracies_learning_rate(save_dir, learning_rate_arr):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Training Epoch vs. Accuracy (Effect of Learning Rate)\")\n",
    "    print(f\"Training Epoch vs. Accuracy (Effect of Learning Rate)\")\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    plt.title(f\"Training Epoch vs. Accuracy (Effect of Learning Rate)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    best_score = 0\n",
    "    best_config = None\n",
    "\n",
    "    for learning_rate in learning_rate_arr:\n",
    "        final_scores = []\n",
    "        epoch_scores = []\n",
    "        # Run an average over multiple trials\n",
    "        for i in range(ntrials):\n",
    "            # Get data and train the network\n",
    "            training_data, validation_data, testing_data = get_data()\n",
    "            nn = BPNN(best_nc, verbose=False)\n",
    "            final_score, eval_scores, eval_scores_deltas, conv_time = nn.train(training_data,\n",
    "                                                                               max_epochs=max_epochs,\n",
    "                                                                               batch_size=best_b,\n",
    "                                                                               learning_rate=learning_rate,\n",
    "                                                                               evaluation_data=validation_data,\n",
    "                                                                               evaluation_treshold=None)\n",
    "\n",
    "            final_scores.append(final_score)\n",
    "            epoch_scores.append(eval_scores)\n",
    "\n",
    "        # Compute the averages over the specified number of trials\n",
    "        final_score_avg = np.average(final_scores)\n",
    "        epoch_scores = np.mean(epoch_scores, axis=0)\n",
    "\n",
    "        print(f'{learning_rate} => {final_score_avg}')\n",
    "        if final_score_avg > best_score:\n",
    "            best_score = final_score_avg\n",
    "            best_config = learning_rate\n",
    "\n",
    "        plt.plot(epoch_scores, label=f'{learning_rate} - {final_score_avg}')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(f'{save_dir}/bpnn_lr_vs_acc', dpi=100)\n",
    "\n",
    "    return best_config\n",
    "\n",
    "\n",
    "learning_rate_arr = [3, 2, 1, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.001]\n",
    "best_lr = plot_accuracies_learning_rate(\"img\", learning_rate_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the convergence curve of BPNN\n",
    "\"\"\"\n",
    "\n",
    "training_data, validation_data, testing_data, ndimen = get_data()\n",
    "\n",
    "nn = BPNN(best_nc, verbose=True)\n",
    "final_score, eval_scores, eval_scores_deltas, nn_conv_time = nn.train(training_data,\n",
    "                                                                      max_epochs=max_epochs,\n",
    "                                                                      batch_size=best_b,\n",
    "                                                                      learning_rate=best_lr,\n",
    "                                                                      evaluation_data=validation_data,\n",
    "                                                                      evaluation_treshold=None)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.title(f\"Training Epoch vs. Accuracy with (Final Model)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.plot(eval_scores, label='Convergence Curve')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(f'img/bpnn_best_model', dpi=100)\n",
    "\n",
    "acc = 0\n",
    "acc0 = 0\n",
    "len0 = 0\n",
    "acc1 = 0\n",
    "len1 = 0\n",
    "\n",
    "for (x, y) in testing_data:\n",
    "    decision = np.argmax(nn.feedforward(x))\n",
    "\n",
    "    if decision == y:\n",
    "        acc += 1\n",
    "    if y == 0:\n",
    "        len0 += 1\n",
    "        if decision == y:\n",
    "            acc0 += 1\n",
    "    if y == 1:\n",
    "        len1 += 1\n",
    "        if decision == y:\n",
    "            acc1 += 1\n",
    "\n",
    "nn_acc = acc / (len0 + len1)\n",
    "# Compute class accuracies\n",
    "nn_acc0 = acc0 / len0\n",
    "nn_acc1 = acc1 / len1\n",
    "\n",
    "print(f'Overall Testing Accuracy: {nn_acc}')\n",
    "print(f'Class 0 Testing Accuracy: {nn_acc0}')\n",
    "print(f'Class 1 Testing Accuracy: {nn_acc1}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}